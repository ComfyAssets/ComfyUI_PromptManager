"""ComfyUI integration utilities for PromptManager.

This module provides deep integration with ComfyUI's metadata system to ensure that
PromptManager-generated prompts appear correctly in standard ComfyUI image metadata.
It patches core ComfyUI components to bridge the gap between PromptManager's custom
nodes and ComfyUI's standard metadata extraction.

Key features:
- Automatic patching of ComfyUI's SaveImage node
- Thread-safe prompt registration and retrieval
- Cross-thread prompt context sharing
- Standard metadata format compatibility
- Automatic cleanup of old prompt registrations

The integration works by:
1. PromptManager nodes register their prompts during execution
2. SaveImage node is patched to include registered prompts in metadata
3. PromptManager class_type is changed to CLIPTextEncode for parser compatibility
4. Standard tools can then extract prompts from the generated images

Typical usage:
    from utils.comfyui_integration import get_comfyui_integration
    
    integration = get_comfyui_integration()
    integration.register_prompt(node_id, prompt_text, metadata)
    # Generated images will now include this prompt in their metadata

This integration is essential for:
- Third-party tool compatibility
- Standard metadata parsers
- Workflow sharing and reproduction
- Integration with existing ComfyUI ecosystems
"""

import threading
import time
import json
from typing import Dict, Any, Optional

try:
    from .logging_config import get_logger
except ImportError:
    import logging

    def get_logger(name: str):
        logger = logging.getLogger(name)
        if not logger.handlers:
            handler = logging.StreamHandler()
            handler.setFormatter(
                logging.Formatter(
                    "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                )
            )
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger


class ComfyUIMetadataIntegration:
    """Integrates PromptManager with ComfyUI's standard metadata system.
    
    This singleton class manages the integration between PromptManager custom nodes
    and ComfyUI's standard metadata system. It ensures that prompts generated by
    PromptManager appear in the standard ComfyUI metadata format for compatibility
    with third-party tools and parsers.
    
    The integration uses thread-local storage combined with global tracking to
    handle prompt context across different execution threads, which is necessary
    because ComfyUI executions may span multiple threads.
    
    Key responsibilities:
    - Register prompts from PromptManager nodes during execution
    - Patch SaveImage to include PromptManager prompts in metadata
    - Convert PromptManager class_type to CLIPTextEncode for compatibility
    - Manage prompt lifecycle and cleanup
    """
    
    def __init__(self):
        """Initialize the ComfyUI integration system.
        
        Sets up prompt tracking data structures. Patching is now done lazily
        when the first PromptManager node executes, rather than at module load.
        This prevents affecting workflows that don't use PromptManager.
        """
        if hasattr(self, '_initialized'):
            return

        self.logger = get_logger('prompt_manager.comfyui_integration')
        self.logger.debug(f"Initializing new instance {id(self)}")
        self._current_prompts = {}
        self._thread_local = threading.local()
        self._lock = threading.Lock()
        self._saveimage_patched = False
        self._pending_registry = None
        self._initialized = True
        
        # NOTE: Patching now happens lazily in register_prompt()
        # to avoid affecting workflows that don't use PromptManager
    
    def _ensure_pending_registry(self):
        """Ensure pending registry is initialized.

        Uses sys.modules singleton pattern to ensure the same registry instance
        is used across module reloads. The API can override this with
        set_pending_registry() if needed.
        """
        import sys
        import types

        # Storage key for the singleton registry
        _REGISTRY_STORAGE_KEY = '__promptmanager_pending_registry_singleton__'

        # Get or create the storage module
        if _REGISTRY_STORAGE_KEY not in sys.modules:
            storage_module = types.ModuleType(_REGISTRY_STORAGE_KEY)
            storage_module.registry = None
            sys.modules[_REGISTRY_STORAGE_KEY] = storage_module

        storage = sys.modules[_REGISTRY_STORAGE_KEY]

        # If registry doesn't exist in singleton storage, create it
        if storage.registry is None:
            try:
                # Try multiple import strategies
                PendingPromptRegistry = None

                # Strategy 1: Relative import from utils
                try:
                    from ..src.tracking import PendingPromptRegistry
                except (ImportError, ValueError):
                    pass

                # Strategy 2: Absolute import (when running as package)
                if PendingPromptRegistry is None:
                    try:
                        from promptmanager.src.tracking import PendingPromptRegistry
                    except ImportError:
                        pass

                # Strategy 3: Direct import after path manipulation
                if PendingPromptRegistry is None:
                    import os
                    package_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    if package_root not in sys.path:
                        sys.path.insert(0, package_root)
                    from src.tracking import PendingPromptRegistry

                # Create singleton registry with 24-hour TTL
                storage.registry = PendingPromptRegistry(ttl_seconds=86400)
                self.logger.info("Initialized singleton pending registry for custom node")
            except Exception as e:
                self.logger.warning(f"Could not initialize pending registry: {e}")

        # Use the singleton registry
        self._pending_registry = storage.registry
    
    def register_prompt(self, node_id: str, prompt_text: str, metadata: Dict[str, Any]):
        """
        Register a prompt from PromptManager for inclusion in ComfyUI metadata.
        
        This method is called by PromptManager nodes during execution to register
        their prompt text for later inclusion in image metadata. The prompt is stored
        in both thread-local and global storage to handle cross-thread access scenarios.
        
        On first call, this method will patch SaveImage to enable metadata integration.
        This lazy patching ensures we only affect workflows that actually use PromptManager.
        
        Args:
            node_id: Unique identifier for this prompt (typically the node ID)
            prompt_text: The actual prompt text that was encoded by PromptManager
            metadata: Additional metadata from PromptManager (category, tags, etc.)
        """
        # Lazy patching: patch SaveImage on first PromptManager node execution
        if not self._saveimage_patched:
            with self._lock:
                # Double-check after acquiring lock (thread-safe singleton pattern)
                if not self._saveimage_patched:
                    self.logger.info("First PromptManager node detected - patching SaveImage")
                    self._patch_saveimage_node()
        
        thread_id = threading.current_thread().ident
        
        # Store in thread-local storage
        if not hasattr(self._thread_local, 'prompts'):
            self._thread_local.prompts = {}
        
        self._thread_local.prompts[node_id] = {
            'text': prompt_text,
            'metadata': metadata,
            'timestamp': time.time(),
            'thread_id': thread_id
        }
        
        # Also store globally for cross-thread access
        with self._lock:
            self._current_prompts[f"{thread_id}_{node_id}"] = {
                'text': prompt_text,
                'metadata': metadata,
                'timestamp': time.time(),
                'thread_id': thread_id
            }
        
        self.logger.debug(f"Registered prompt for node {node_id}: {prompt_text[:50]}...")
    
    def get_current_prompt_text(self, node_id: str = None) -> Optional[str]:
        """
        Get the current prompt text for metadata inclusion.
        
        Retrieves the most appropriate prompt text for inclusion in image metadata.
        Uses a fallback strategy: thread-local storage first, then global storage
        for the CURRENT thread only.
        
        CRITICAL: This method will ONLY return prompts from the current thread
        to prevent cross-workflow contamination.
        
        Args:
            node_id: Optional specific node ID to retrieve prompt for
            
        Returns:
            The prompt text string if available, None if no suitable prompt found
        """
        # First try thread-local storage
        if hasattr(self._thread_local, 'prompts'):
            if node_id and node_id in self._thread_local.prompts:
                return self._thread_local.prompts[node_id]['text']
            elif self._thread_local.prompts:
                # Return the most recent prompt from this thread
                latest = max(self._thread_local.prompts.values(), key=lambda x: x['timestamp'])
                return latest['text']
        
        # Fallback to global storage FOR CURRENT THREAD ONLY
        thread_id = threading.current_thread().ident
        with self._lock:
            # Look for prompts from current thread
            thread_prompts = {k: v for k, v in self._current_prompts.items() 
                            if v['thread_id'] == thread_id}
            
            if thread_prompts:
                latest = max(thread_prompts.values(), key=lambda x: x['timestamp'])
                return latest['text']
        
        # If no prompts found for current thread, return None
        # DO NOT fall back to other threads - prevents cross-workflow contamination
        return None
    
    def _patch_saveimage_node(self):
        """
        Patch ComfyUI's SaveImage node to include PromptManager prompts in metadata.
        
        This method modifies ComfyUI's SaveImage.save_images method to automatically
        include PromptManager prompts in the image metadata. The patching:
        
        1. Wraps the original save_images method
        2. Checks if current workflow contains PromptManager nodes
        3. Retrieves current PromptManager prompt text if applicable
        4. Modifies the workflow data to include the prompt
        5. Changes PromptManager class_type to CLIPTextEncode for compatibility
        6. Calls the original method with modified data
        
        The patching is designed to be minimally invasive and maintain full
        compatibility with existing ComfyUI functionality. If ANY error occurs
        in our code, it gracefully falls back to the original behavior.
        """
        try:
            import nodes
            
            if not hasattr(nodes, 'SaveImage'):
                self.logger.warning("SaveImage node not found in ComfyUI nodes")
                return
            
            # Store original save_images method
            original_save_images = nodes.SaveImage.save_images
            integration = self  # Capture self reference
            
            def patched_save_images(self_node, images, filename_prefix="ComfyUI", prompt=None, extra_pnginfo=None):
                """Patched save_images method that includes PromptManager prompts.
                
                CRITICAL: This function must NEVER break image saving. Any errors
                in our code should be caught and logged, then fall through to the
                original save_images method.
                
                Only injects metadata if the workflow actually contains PromptManager nodes.
                """
                try:
                    # CRITICAL: Check if this workflow contains PromptManager nodes
                    has_promptmanager = False
                    if prompt and isinstance(prompt, dict):
                        for node_id, node_data in prompt.items():
                            if isinstance(node_data, dict):
                                class_type = node_data.get('class_type', '')
                                if 'promptmanager' in class_type.lower():
                                    has_promptmanager = True
                                    break
                    
                    # Only inject metadata if this workflow uses PromptManager
                    if not has_promptmanager:
                        integration.logger.debug("Workflow does not contain PromptManager nodes - skipping metadata injection")
                        return original_save_images(self_node, images, filename_prefix, prompt, extra_pnginfo)
                    
                    # Get current prompt text from PromptManager
                    current_prompt_text = integration.get_current_prompt_text()
                    
                    if current_prompt_text:
                        integration.logger.debug(f"Including PromptManager prompt in SaveImage metadata: {current_prompt_text[:50]}...")
                        
                        # If no prompt provided, create one with our text
                        if prompt is None:
                            prompt = {}
                        
                        # Ensure prompt has the standard structure ComfyUI expects
                        if not isinstance(prompt, dict):
                            prompt = {}
                        
                        # Find PromptManager nodes and fix them for standard parser compatibility
                        prompt_updated = False
                        for node_id, node_data in prompt.items():
                            if isinstance(node_data, dict):
                                class_type = node_data.get('class_type', '')
                                if 'promptmanager' in class_type.lower():
                                    # Update the inputs to include our actual prompt text
                                    if 'inputs' not in node_data:
                                        node_data['inputs'] = {}
                                    node_data['inputs']['text'] = current_prompt_text
                                    
                                    # SIMPLE FIX: Change class_type to CLIPTextEncode for standard parser compatibility
                                    # Keep original class_type in metadata for reference
                                    if '_meta' not in node_data:
                                        node_data['_meta'] = {}
                                    node_data['_meta']['original_class_type'] = class_type
                                    node_data['class_type'] = 'CLIPTextEncode'
                                    
                                    prompt_updated = True
                                    integration.logger.debug(f"Fixed PromptManager node {node_id} - changed class_type to CLIPTextEncode for compatibility")
                        
                        # If no PromptManager nodes found, add a standalone one
                        if not prompt_updated:
                            virtual_node_id = "promptmanager_text"
                            prompt[virtual_node_id] = {
                                "class_type": "CLIPTextEncode",  # Use CLIPTextEncode for compatibility
                                "inputs": {
                                    "text": current_prompt_text
                                },
                                "_meta": {
                                    "original_class_type": "PromptManager",
                                    "virtual": True
                                }
                            }
                            integration.logger.debug("Added standalone CLIPTextEncode node with PromptManager text")
                
                except Exception as e:
                    # CRITICAL: Never let our errors break image saving
                    integration.logger.error(f"Error in PromptManager metadata integration: {e}")
                    integration.logger.warning("Falling back to original SaveImage behavior")
                    # Continue with original behavior below
                
                # ALWAYS call original method, even if our code failed
                return original_save_images(self_node, images, filename_prefix, prompt, extra_pnginfo)
            
            # Apply the patch
            nodes.SaveImage.save_images = patched_save_images
            self._saveimage_patched = True
            self.logger.info("Successfully patched SaveImage node for PromptManager integration")
            
        except Exception as e:
            self.logger.error(f"Failed to patch SaveImage node: {e}")
            self.logger.warning("PromptManager prompts may not appear in standard ComfyUI metadata")
            # Don't raise - allow module to continue loading
            # Don't raise - allow module to continue loading
    
    def get_output_directory(self):
        """
        Get the ComfyUI output directory for saving images.
        
        Returns the output directory path, attempting to get it from ComfyUI
        if available, otherwise returning a default path.
        """
        try:
            # Try to get from ComfyUI's folder_paths module
            import folder_paths
            return folder_paths.get_output_directory()
        except ImportError:
            # Fallback to a default directory
            import os
            default_dir = os.path.join(os.path.expanduser("~"), "ComfyUI", "output")
            os.makedirs(default_dir, exist_ok=True)
            return default_dir

    def set_pending_registry(self, registry):
        """Set the pending prompt registry for conditional saving.

        Args:
            registry: PendingPromptRegistry instance from API
        """
        # ALWAYS replace with the API's registry - it's the source of truth
        old_id = id(self._pending_registry) if self._pending_registry else None
        self._pending_registry = registry
        new_id = id(self._pending_registry) if self._pending_registry else None

        self.logger.debug(f"Updated _pending_registry: {old_id} â†’ {new_id}")
        if registry:
            self.logger.info(f"Set pending registry from API (new id={new_id})")

    def get_pending_registry(self):
        """Get the pending prompt registry if available.

        Creates a default registry if one doesn't exist yet.

        Returns:
            PendingPromptRegistry instance or None if unavailable
        """
        # Ensure registry is initialized
        self._ensure_pending_registry()

        if self._pending_registry:
            registry_id = id(self._pending_registry)
            registry_count = self._pending_registry.get_count()
            self.logger.debug(f"Returning pending registry (id={registry_id}, count={registry_count})")
        else:
            self.logger.debug("Pending registry not available")

        return self._pending_registry
     
    def cleanup_old_prompts(self, max_age_seconds: int = 600):
        """
        Clean up old prompt registrations.
        
        Removes prompt registrations that are older than the specified age to
        prevent memory leaks and ensure that only recent, relevant prompts are
        used for metadata inclusion.
        
        Clears both global and thread-local storage.
        
        Args:
            max_age_seconds: Maximum age in seconds before a prompt registration
                           is considered stale and removed (default: 600 seconds/10 minutes)
        """
        current_time = time.time()
        
        # Clean global storage
        with self._lock:
            old_keys = [
                key for key, prompt_data in self._current_prompts.items()
                if current_time - prompt_data['timestamp'] > max_age_seconds
            ]
            
            for key in old_keys:
                del self._current_prompts[key]
        
        # Clean thread-local storage
        if hasattr(self._thread_local, 'prompts'):
            old_node_ids = [
                node_id for node_id, prompt_data in self._thread_local.prompts.items()
                if current_time - prompt_data['timestamp'] > max_age_seconds
            ]
            
            for node_id in old_node_ids:
                del self._thread_local.prompts[node_id]
            
            if old_node_ids:
                self.logger.debug(f"Cleaned up {len(old_node_ids)} thread-local prompts")
        
        if old_keys:
            self.logger.debug(f"Cleaned up {len(old_keys)} global prompt registrations")


# Global instance using sys.modules pattern (survives module reloads)
# Same pattern as SingletonTracker to handle ComfyUI's dynamic module loading
_INTEGRATION_STORAGE_KEY = '__promptmanager_comfyui_integration_singleton__'

def get_comfyui_integration() -> ComfyUIMetadataIntegration:
    """Get the global ComfyUI integration instance.

    Uses sys.modules storage to ensure the same instance is returned even when
    this module is reloaded. This is critical for ComfyUI's dynamic module loading.

    Returns:
        The singleton ComfyUIMetadataIntegration instance
    """
    import sys
    import types
    import os

    debug = os.getenv("PROMPTMANAGER_DEBUG", "0") == "1"

    # Get or create the storage module
    if _INTEGRATION_STORAGE_KEY not in sys.modules:
        if debug:
            print(f"[ComfyUI Integration] Creating storage module")
        storage_module = types.ModuleType(_INTEGRATION_STORAGE_KEY)
        storage_module.instance = None
        sys.modules[_INTEGRATION_STORAGE_KEY] = storage_module

    storage = sys.modules[_INTEGRATION_STORAGE_KEY]

    # Get or create the singleton instance
    if storage.instance is None:
        if debug:
            print(f"[ComfyUI Integration] Creating new singleton instance")
        storage.instance = ComfyUIMetadataIntegration()
        if debug:
            print(f"[ComfyUI Integration] Singleton instance created: {id(storage.instance)}")

    return storage.instance
