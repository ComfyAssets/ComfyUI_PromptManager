"""PNG metadata extraction utilities.

This module provides utilities for extracting metadata from PNG files,
including ComfyUI workflow data and generation parameters.
"""

import json
import struct
import zlib
from typing import Any, Dict, Optional, Tuple
from pathlib import Path

from .logging import get_logger

logger = get_logger("promptmanager.utils.metadata_extractor")


class MetadataExtractor:
    """Extract metadata from PNG images generated by ComfyUI."""
    
    # PNG chunk type codes
    PNG_SIGNATURE = b'\x89PNG\r\n\x1a\n'
    CHUNK_IEND = b'IEND'
    CHUNK_TEXT = b'tEXt'
    CHUNK_ITXT = b'iTXt'
    
    # ComfyUI metadata keys
    COMFYUI_WORKFLOW_KEY = "workflow"
    COMFYUI_PROMPT_KEY = "prompt"
    
    @classmethod
    def extract_from_file(cls, file_path: str) -> Dict[str, Any]:
        """Extract all metadata from a PNG file.
        
        Args:
            file_path: Path to PNG file
            
        Returns:
            Dictionary containing extracted metadata
        """
        path = Path(file_path)
        
        if not path.exists():
            logger.error(f"File not found: {file_path}")
            return {}
        
        if not path.suffix.lower() == '.png':
            logger.warning(f"Not a PNG file: {file_path}")
            return {}
        
        try:
            with open(file_path, 'rb') as f:
                return cls._extract_from_stream(f)
        except Exception as e:
            logger.error(f"Error extracting metadata from {file_path}: {e}")
            return {}
    
    @classmethod
    def _extract_from_stream(cls, stream) -> Dict[str, Any]:
        """Extract metadata from a file stream.
        
        Args:
            stream: File stream object
            
        Returns:
            Dictionary containing extracted metadata
        """
        metadata = {
            "text_chunks": {},
            "workflow": None,
            "prompt": None,
            "generation_params": {},
            "raw_chunks": []
        }
        
        # Verify PNG signature
        signature = stream.read(8)
        if signature != cls.PNG_SIGNATURE:
            logger.error("Invalid PNG signature")
            return metadata
        
        # Read chunks until IEND
        while True:
            chunk_data = cls._read_chunk(stream)
            if not chunk_data:
                break
            
            chunk_type, data = chunk_data
            
            if chunk_type == cls.CHUNK_IEND:
                break
            elif chunk_type == cls.CHUNK_TEXT:
                key, value = cls._parse_text_chunk(data)
                if key and value:
                    metadata["text_chunks"][key] = value
                    
                    # Check for ComfyUI data
                    if key == cls.COMFYUI_WORKFLOW_KEY:
                        metadata["workflow"] = cls._parse_json_safely(value)
                    elif key == cls.COMFYUI_PROMPT_KEY:
                        metadata["prompt"] = cls._parse_json_safely(value)
                    elif key == "parameters":
                        metadata["generation_params"] = cls._parse_generation_params(value)
            elif chunk_type == cls.CHUNK_ITXT:
                key, value = cls._parse_itxt_chunk(data)
                if key and value:
                    metadata["text_chunks"][key] = value
        
        return metadata
    
    @classmethod
    def _read_chunk(cls, stream) -> Optional[Tuple[bytes, bytes]]:
        """Read a PNG chunk from stream.
        
        Args:
            stream: File stream
            
        Returns:
            Tuple of (chunk_type, data) or None
        """
        # Read chunk length (4 bytes)
        length_data = stream.read(4)
        if len(length_data) < 4:
            return None
        
        length = struct.unpack('>I', length_data)[0]
        
        # Read chunk type (4 bytes)
        chunk_type = stream.read(4)
        if len(chunk_type) < 4:
            return None
        
        # Read chunk data
        data = stream.read(length) if length > 0 else b''
        
        # Read and verify CRC (4 bytes)
        crc = stream.read(4)
        if len(crc) < 4:
            return None
        
        # Verify CRC
        expected_crc = struct.unpack('>I', crc)[0]
        actual_crc = zlib.crc32(chunk_type + data) & 0xffffffff
        
        if expected_crc != actual_crc:
            logger.warning(f"CRC mismatch for chunk {chunk_type}")
        
        return chunk_type, data
    
    @classmethod
    def _parse_text_chunk(cls, data: bytes) -> Tuple[Optional[str], Optional[str]]:
        """Parse a tEXt chunk.
        
        Args:
            data: Chunk data
            
        Returns:
            Tuple of (key, value) or (None, None)
        """
        try:
            # Find null separator
            null_index = data.index(b'\x00')
            key = data[:null_index].decode('latin-1')
            value = data[null_index + 1:].decode('latin-1')
            return key, value
        except (ValueError, UnicodeDecodeError) as e:
            logger.debug(f"Error parsing text chunk: {e}")
            return None, None
    
    @classmethod
    def _parse_itxt_chunk(cls, data: bytes) -> Tuple[Optional[str], Optional[str]]:
        """Parse an iTXt chunk (international text).
        
        Args:
            data: Chunk data
            
        Returns:
            Tuple of (key, value) or (None, None)
        """
        try:
            # Find null separators
            null_index = data.index(b'\x00')
            key = data[:null_index].decode('latin-1')
            
            # Skip compression flag and method
            remaining = data[null_index + 1:]
            if len(remaining) < 2:
                return key, None
            
            compression_flag = remaining[0]
            compression_method = remaining[1]
            remaining = remaining[2:]
            
            # Find language tag and translated keyword (skip them)
            null_index = remaining.index(b'\x00')
            remaining = remaining[null_index + 1:]
            
            null_index = remaining.index(b'\x00')
            text_data = remaining[null_index + 1:]
            
            # Decompress if needed
            if compression_flag == 1:
                text_data = zlib.decompress(text_data)
            
            value = text_data.decode('utf-8')
            return key, value
        except (ValueError, UnicodeDecodeError, zlib.error) as e:
            logger.debug(f"Error parsing iTXt chunk: {e}")
            return None, None
    
    @classmethod
    def _parse_json_safely(cls, text: str) -> Optional[Dict[str, Any]]:
        """Safely parse JSON text.
        
        Args:
            text: JSON string
            
        Returns:
            Parsed JSON or None
        """
        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            logger.debug(f"Error parsing JSON: {e}")
            return None
    
    @classmethod
    def _parse_generation_params(cls, params_text: str) -> Dict[str, Any]:
        """Parse generation parameters from text.
        
        Args:
            params_text: Parameters text (e.g., from Automatic1111)
            
        Returns:
            Dictionary of parsed parameters
        """
        params = {}
        
        # Parse common format: "key: value, key: value"
        parts = params_text.split(',')
        for part in parts:
            if ':' in part:
                key, value = part.split(':', 1)
                key = key.strip().lower().replace(' ', '_')
                value = value.strip()
                
                # Try to convert to appropriate type
                if value.isdigit():
                    value = int(value)
                elif value.replace('.', '', 1).isdigit():
                    value = float(value)
                elif value.lower() in ('true', 'false'):
                    value = value.lower() == 'true'
                
                params[key] = value
        
        # Handle special cases
        if 'negative_prompt' in params_text:
            # Extract negative prompt which might contain commas
            neg_start = params_text.find('Negative prompt:')
            if neg_start != -1:
                neg_end = params_text.find('\n', neg_start)
                if neg_end == -1:
                    neg_end = len(params_text)
                neg_prompt = params_text[neg_start + 16:neg_end].strip()
                params['negative_prompt'] = neg_prompt
        
        return params
    
    @classmethod
    def extract_workflow(cls, file_path: str) -> Optional[Dict[str, Any]]:
        """Extract ComfyUI workflow from PNG.
        
        Args:
            file_path: Path to PNG file
            
        Returns:
            Workflow dictionary or None
        """
        metadata = cls.extract_from_file(file_path)
        return metadata.get("workflow")
    
    @classmethod
    def extract_prompt(cls, file_path: str) -> Optional[Dict[str, Any]]:
        """Extract ComfyUI prompt from PNG.
        
        Args:
            file_path: Path to PNG file
            
        Returns:
            Prompt dictionary or None
        """
        metadata = cls.extract_from_file(file_path)
        return metadata.get("prompt")
    
    @classmethod
    def extract_generation_info(cls, file_path: str) -> Dict[str, Any]:
        """Extract generation information from PNG.
        
        Args:
            file_path: Path to PNG file
            
        Returns:
            Dictionary with generation info
        """
        metadata = cls.extract_from_file(file_path)
        
        info = {
            "prompt": "",
            "negative_prompt": "",
            "checkpoint": "",
            "sampler": "",
            "steps": 0,
            "cfg_scale": 0.0,
            "seed": -1,
            "model_hash": ""
        }
        
        # Try to extract from ComfyUI prompt data
        prompt_data = metadata.get("prompt")
        if prompt_data:
            # Look for KSampler node
            for node_id, node in prompt_data.items():
                if isinstance(node, dict):
                    class_type = node.get("class_type", "")
                    
                    if class_type == "KSampler":
                        inputs = node.get("inputs", {})
                        info["sampler"] = inputs.get("sampler_name", "")
                        info["steps"] = inputs.get("steps", 0)
                        info["cfg_scale"] = inputs.get("cfg", 0.0)
                        info["seed"] = inputs.get("seed", -1)
                    
                    elif class_type == "CheckpointLoaderSimple":
                        inputs = node.get("inputs", {})
                        info["checkpoint"] = inputs.get("ckpt_name", "")
                    
                    elif class_type == "CLIPTextEncode":
                        inputs = node.get("inputs", {})
                        text = inputs.get("text", "")
                        # Determine if positive or negative based on connections
                        if "positive" in str(node).lower() or not info["prompt"]:
                            info["prompt"] = text
                        else:
                            info["negative_prompt"] = text
        
        # Try to extract from generation params (Automatic1111 format)
        gen_params = metadata.get("generation_params", {})
        if gen_params:
            info.update({
                k: gen_params.get(k, info[k])
                for k in info.keys()
                if k in gen_params
            })
        
        return info
    
    @classmethod
    def embed_metadata(cls, file_path: str, metadata: Dict[str, Any]) -> bool:
        """Embed metadata into a PNG file.
        
        Args:
            file_path: Path to PNG file
            metadata: Metadata to embed
            
        Returns:
            True if successful
        """
        try:
            # Read original file
            with open(file_path, 'rb') as f:
                data = f.read()
            
            # Find IEND chunk position
            iend_pos = data.rfind(cls.CHUNK_IEND)
            if iend_pos == -1:
                logger.error("IEND chunk not found")
                return False
            
            # Back up to get the full IEND chunk
            iend_pos -= 8  # Length (4) + CRC (4)
            
            # Prepare new chunks
            new_chunks = []
            
            # Add workflow if present
            if "workflow" in metadata:
                chunk = cls._create_text_chunk(
                    cls.COMFYUI_WORKFLOW_KEY,
                    json.dumps(metadata["workflow"])
                )
                new_chunks.append(chunk)
            
            # Add prompt if present
            if "prompt" in metadata:
                chunk = cls._create_text_chunk(
                    cls.COMFYUI_PROMPT_KEY,
                    json.dumps(metadata["prompt"])
                )
                new_chunks.append(chunk)
            
            # Add other metadata
            for key, value in metadata.items():
                if key not in ("workflow", "prompt"):
                    if isinstance(value, (dict, list)):
                        value = json.dumps(value)
                    elif not isinstance(value, str):
                        value = str(value)
                    
                    chunk = cls._create_text_chunk(key, value)
                    new_chunks.append(chunk)
            
            # Reconstruct file
            new_data = (
                data[:iend_pos] +
                b''.join(new_chunks) +
                data[iend_pos:]
            )
            
            # Write back
            with open(file_path, 'wb') as f:
                f.write(new_data)
            
            return True
            
        except Exception as e:
            logger.error(f"Error embedding metadata: {e}")
            return False
    
    @classmethod
    def _create_text_chunk(cls, key: str, value: str) -> bytes:
        """Create a tEXt PNG chunk.
        
        Args:
            key: Metadata key
            value: Metadata value
            
        Returns:
            Complete chunk bytes
        """
        # Prepare data
        data = key.encode('latin-1') + b'\x00' + value.encode('latin-1')
        
        # Calculate length
        length = len(data)
        
        # Calculate CRC
        crc = zlib.crc32(cls.CHUNK_TEXT + data) & 0xffffffff
        
        # Build chunk
        chunk = (
            struct.pack('>I', length) +
            cls.CHUNK_TEXT +
            data +
            struct.pack('>I', crc)
        )
        
        return chunk
